# -*- coding: utf-8 -*-
"""llama_inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYVrzBT0ZqxsSQ84Qx2hwOaYuKQm1KWR
"""

!pip install -U transformers

!huggingface-cli login

import transformers
import torch

model_id = "meta-llama/Meta-Llama-3.1-8B-Instruct"

pipeline = transformers.pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={"torch_dtype": torch.bfloat16},
    device_map="auto",
)

messages = [
    {"role": "system", "content": "You are a pirate chatbot who always responds in pirate speak!"},
    {"role": "user", "content": "Who are you?"},
]

outputs = pipeline(
    messages,
    max_new_tokens=256,
)
print(outputs[0]["generated_text"][-1])

def make_fewshot_prompt(text, categories):
    categories_str = "\n".join(f"- {cat}" for cat in categories)
    prompt = (
        "Classify the following news headline into exactly one of these categories. "
        "Reply with the category label only.\n"
        "Categories:\n"
        f"{categories_str}\n\n"
        "Headline: \"OPEC increases crude oil output in July.\"\n"
        "Category: supply-increase-commodity\n\n"
        "Headline: \"Demand for crude oil declines as electric vehicles gain popularity.\"\n"
        "Category: demand-decrease-commodity\n\n"
        "Headline: \"Saudi Arabia's crude oil exports hit a new high.\"\n"
        "Category: exports-up\n\n"
        "Headline: \"U.S. reduces crude oil imports from Russia.\"\n"
        "Category: imports-down\n\n"
        "Headline: \"Major pipeline disruption cuts crude oil supply.\"\n"
        "Category: supply-decrease-commodity\n\n"
        "Headline: \"Growing airline industry boosts crude oil demand.\"\n"
        "Category: demand-increase-commodity\n\n"
        "Headline: \"India ramps up crude oil imports to meet rising demand.\"\n"
        "Category: imports-up\n\n"
        "Headline: \"Venezuela experiences decline in crude oil exports.\"\n"
        "Category: exports-down\n\n"
        "Headline: \"Large crude oil spill reported off the coast.\"\n"
        "Category: spill-commodity\n\n"
        "Headline: \"Crude oil prices remain unchanged despite market volatility.\"\n"
        "Category: commodity-price-unchanged\n\n"
        "Headline: \"No significant changes in global crude oil supply this month.\"\n"
        "Category: supply-unchanged-commodity\n\n"
        "Headline: \"Demand for crude oil stays steady amid economic uncertainty.\"\n"
        "Category: demand-unchanged-commodity\n\n"
        "Headline: \"Saudi Arabia maintains steady crude oil export levels.\"\n"
        "Category: exports-unchanged\n\n"
        "Headline: \"U.S. crude oil import volumes remain unchanged.\"\n"
        "Category: imports-unchanged\n\n"
        f"Headline: \"{text}\"\n"
        "REMEMBER: Only respond with ONE of the category labels above and nothing else."
        "Category:"
    )
    return prompt

selected_categories = [
    "supply-increase-commodity",
    "demand-decrease-commodity",
    "exports-up",
    "imports-down",
    "supply-decrease-commodity",
    "demand-increase-commodity",
    "imports-up",
    "exports-down",
    "spill-commodity",
    "commodity-price-unchanged",
    "supply-unchanged-commodity",
    "demand-unchanged-commodity",
    "exports-unchanged",
    "imports-unchanged"
]

headline = "demand for Crude Oil increases"
prompt = make_fewshot_prompt(headline, selected_categories)

output = pipeline(prompt, max_new_tokens=5, do_sample=False)
generated = output[0]['generated_text'][len(prompt):].strip()
predicted_category = generated.split()[0]
print("Predicted category:", predicted_category)

headlines = [
    "Demand for crude oil declines as electric vehicles gain popularity",
    "OPEC increases crude oil output in July",
    "Large crude oil spill reported off the coast"
]

predicted_categories = []

for headline in headlines:
    prompt = make_fewshot_prompt(headline, selected_categories)
    output = pipeline(prompt, max_new_tokens=5, do_sample=False)
    generated = output[0]['generated_text'][len(prompt):].strip()
    predicted_category = generated.split()[0]
    predicted_categories.append(predicted_category)

print(predicted_categories)

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Adjust the path as needed for your Google Drive folder structure
file_path = '/content/drive/MyDrive/Thesis files/Testing_files/Longtermtest/Crude long term price prediction.parquet'
df = pd.read_parquet(file_path)

# Preview to verify

df

titles = df["TITLE"].tolist()

len(titles)

predicted_categories = []

for headline in titles:
    # Step 1: First try with standard prompt
    prompt = make_fewshot_prompt(headline, selected_categories)
    output = pipeline(prompt, max_new_tokens=5, do_sample=False)
    generated = output[0]['generated_text'][len(prompt):].strip()
    predicted_category = generated.split()[0]

    # Step 2: Check validity
    if predicted_category not in selected_categories:
        # Step 3: Retry with stricter prompt
        strict_prompt = (
            f"Select ONLY ONE category from this list (no explanation, only the label):\n"
            f"{', '.join(selected_categories)}\n"
            f"Headline: \"{headline}\"\n"
            "Category:"
        )
        output2 = pipeline(strict_prompt, max_new_tokens=5, do_sample=False)
        generated2 = output2[0]['generated_text'][len(strict_prompt):].strip()
        predicted_category2 = generated2.split()[0]

        # Step 4: Final check
        if predicted_category2 in selected_categories:
            predicted_categories.append(predicted_category2)
        else:
            predicted_categories.append("No Clear Event For Crude Oil Detected")  # Or any fallback
    else:
        predicted_categories.append(predicted_category)

print(predicted_categories)

# pip install tqdm  # (run once if you don't have it)
from tqdm.auto import tqdm

predicted_categories = []
fallback_count = 0

pbar = tqdm(titles, desc="Classifying headlines", unit="headline")

for headline in pbar:
    # Step 1: First try with standard prompt
    prompt = make_fewshot_prompt(headline, selected_categories)
    output = pipeline(prompt, max_new_tokens=5, do_sample=False)
    generated = output[0]['generated_text'][len(prompt):].strip()
    predicted_category = generated.split()[0] if generated else ""

    # Step 2: Check validity
    if predicted_category not in selected_categories:
        # Step 3: Retry with stricter prompt
        strict_prompt = (
            f"Select ONLY ONE category from this list (no explanation, only the label):\n"
            f"{', '.join(selected_categories)}\n"
            f"Headline: \"{headline}\"\n"
            "Category:"
        )
        output2 = pipeline(strict_prompt, max_new_tokens=5, do_sample=False)
        generated2 = output2[0]['generated_text'][len(strict_prompt):].strip()
        predicted_category2 = generated2.split()[0] if generated2 else ""

        # Step 4: Final check
        if predicted_category2 in selected_categories:
            predicted_categories.append(predicted_category2)
        else:
            predicted_categories.append("No Clear Event For Crude Oil Detected")
        fallback_count += 1
    else:
        predicted_categories.append(predicted_category)

    # Update the postfix on the progress bar
    pbar.set_postfix({"fallbacks": fallback_count})

pbar.close()
print(predicted_categories)

len(predicted_categories)

df['predicted_category'] = predicted_categories
display(df.head())

df.to_parquet("final inferred llama.parquet")

from google.colab import files
files.download("final inferred llama.parquet")

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score

def get_performance_metrics(df_test):
  y_test = df_test.label
  y_pred = df_test.predictions

  print("Confusion Matrix:")
  print(confusion_matrix(y_test, y_pred))

  print("\nClassification Report:")
  print(classification_report(y_test, y_pred))

  print("Balanced Accuracy Score:", balanced_accuracy_score(y_test, y_pred))
  print("Accuracy Score:", accuracy_score(y_test, y_pred))

from sklearn.metrics import classification_report

# Ensure consistent labels by taking the union of unique labels from both columns
all_labels = sorted(list(set(df['CATEGORY'].unique()) | set(df['predicted_category'].unique())))

print(classification_report(df['CATEGORY'], df['predicted_category'], labels=all_labels, zero_division=0))

count = (df['predicted_category'] == 'No Clear Event For Crude Oil Detected').sum()
print(f"Number of 'No Clear Event For Crude Oil Detected': {count}")

